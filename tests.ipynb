{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "from preprocess import *\n",
    "from attacks import *\n",
    "from models import *\n",
    "from utils import *\n",
    "from generate_attacks import *\n",
    "\n",
    "device = 'cuda'\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(root = '/home/aminul/data',train = True, \n",
    "                           transform = transforms.ToTensor(), download = False)\n",
    "test_set = datasets.MNIST(root = '/home/aminul/data',train = False, \n",
    "                          transform = transforms.ToTensor(), download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,100,True)\n",
    "test_loader = DataLoader(test_set,100,False)\n",
    "\n",
    "train_loader_2 = DataLoader(train_set,1,True)\n",
    "test_loader_2 = DataLoader(test_set,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model1 = CNN()\n",
    "\n",
    "opt_1 = torch.optim.SGD(model1.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:11<00:00, 53.96it/s]\n",
      "  2%|▏         | 9/600 [00:00<00:07, 80.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch: [1/5]  loss: [2.09] Accuracy [40.56] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:07<00:00, 81.32it/s]\n",
      "  2%|▏         | 9/600 [00:00<00:07, 81.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch: [2/5]  loss: [0.52] Accuracy [85.02] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:07<00:00, 81.77it/s]\n",
      "  2%|▏         | 9/600 [00:00<00:07, 81.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch: [3/5]  loss: [0.32] Accuracy [90.27] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:08<00:00, 68.42it/s]\n",
      "  1%|          | 7/600 [00:00<00:09, 65.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch: [4/5]  loss: [0.25] Accuracy [92.42] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:08<00:00, 68.39it/s]\n",
      "  8%|▊         | 8/100 [00:00<00:01, 78.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch: [5/5]  loss: [0.20] Accuracy [93.97] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 80.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Loss: [0.16] Accuracy [95.32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = train(model1,train_loader,num_epochs,opt_1,criterion,device)\n",
    "test(model1,test_loader,criterion,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 25/10000 [00:00<00:41, 241.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Adversarial Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 568.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Loss: [1.33] Accuracy [55.07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adv_loader = generateFGSM(test_loader_2,model1,device,0.1,criterion)\n",
    "test(model1,adv_loader,criterion,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 4/10000 [00:00<04:27, 37.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Adversarial Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 572.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Loss: [6.34] Accuracy [0.97]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eps= 0.1\n",
    "momentum = 0.9\n",
    "max_iter = 10\n",
    "adv_loader = generateMIFGSM(test_loader_2,model1,device,eps,momentum,max_iter,criterion)\n",
    "test(model1,adv_loader,criterion,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool(net, image, device, num_classes=10, overshoot=0.02, max_iter=10):\n",
    "    \n",
    "    net,image = net.to(device),image.to(device)\n",
    "    \n",
    "    f_image = net(image).cpu().data.numpy().flatten()\n",
    "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
    "\n",
    "    I = I[0:num_classes]\n",
    "    label = I[0]\n",
    "\n",
    "    input_shape = image.cpu().detach().numpy().shape\n",
    "    pert_image = copy.deepcopy(image)\n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "\n",
    "    loop_i = 0\n",
    "\n",
    "    x = torch.tensor(pert_image[None, :],requires_grad=True).to(device)\n",
    "    \n",
    "    fs = net.forward(x[0])\n",
    "    fs_list = [fs[0,I[k]] for k in range(num_classes)]\n",
    "    k_i = label\n",
    "\n",
    "    while k_i == label and loop_i < max_iter:\n",
    "\n",
    "        pert = np.inf\n",
    "        fs[0, I[0]].backward(retain_graph=True)\n",
    "        grad_orig = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "        for k in range(1, num_classes):\n",
    "            \n",
    "            #x.zero_grad()\n",
    "            \n",
    "            fs[0, I[k]].backward(retain_graph=True)\n",
    "            cur_grad = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "            # set new w_k and new f_k\n",
    "            w_k = cur_grad - grad_orig\n",
    "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
    "\n",
    "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
    "\n",
    "            # determine which w_k to use\n",
    "            if pert_k < pert:\n",
    "                pert = pert_k\n",
    "                w = w_k\n",
    "\n",
    "        # compute r_i and r_tot\n",
    "        # Added 1e-4 for numerical stability\n",
    "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
    "        r_tot = np.float32(r_tot + r_i)\n",
    "\n",
    "        pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).to(device)\n",
    "\n",
    "        x = torch.tensor(pert_image, requires_grad=True).to(device)\n",
    "        fs = net.forward(x[0])\n",
    "        k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    r_tot = (1+overshoot)*r_tot\n",
    "\n",
    "    return r_tot, loop_i, label, k_i, pert_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def generateDeepFool(test_loader,model,device,num_classes=10, overshoot=0.02, max_iter=10):\n",
    "    adv_img = []\n",
    "    l = []\n",
    "     \n",
    "    print(\"Generating Adversarial Images\")\n",
    "    iterator = tqdm(test_loader,ncols=0, leave=False)\n",
    "    for data,labels in iterator:\n",
    "        _,_,_,_,x1 = deepfool(model,data,device,num_classes=10, overshoot=0.02, max_iter=10)\n",
    "        l.append(labels)\n",
    "        x2 = x1.squeeze().cpu().detach().numpy()\n",
    "        adv_img.append(x2)\n",
    "            \n",
    "    x3 = np.array(adv_img)\n",
    "    x3 = x3.reshape(10000,1,28,28)\n",
    "    l = np.array(l)\n",
    "        \n",
    "    features_test = torch.from_numpy(x3)\n",
    "    targets_test = torch.from_numpy(l)\n",
    "\n",
    "    new_dataset = torch.utils.data.TensorDataset(features_test,targets_test)\n",
    "    new_data_loader = torch.utils.data.DataLoader(new_dataset,100,shuffle = False)\n",
    "    \n",
    "    \n",
    "    return new_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Adversarial Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/aminul/anaconda3/envs/pyTorch/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/aminul/anaconda3/envs/pyTorch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  4% 355/10000 [00:37<18:56,  8.49it/s]"
     ]
    }
   ],
   "source": [
    "adv_loader = generateDeepFool(test_loader_2,model1,device,num_classes=10, overshoot=0.02, max_iter=10)\n",
    "test(model1,adv_loader,criterion,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyTorch]",
   "language": "python",
   "name": "conda-env-pyTorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
